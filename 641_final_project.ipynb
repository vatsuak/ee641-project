{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d66_xxoUWyRK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root = \"drive/MyDrive/641\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVoqCaeJX_6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator"
      ],
      "metadata": {
        "id": "LNMsDocEW6oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1), # Pads the input tensor using the reflection of the input boundary\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features), \n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_block):\n",
        "        super(GeneratorResNet, self).__init__()\n",
        "        \n",
        "        channels = input_shape[0]\n",
        "        \n",
        "        # Initial Convolution Block\n",
        "        out_features = 64\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(channels, out_features, 7),\n",
        "            nn.InstanceNorm2d(out_features),\n",
        "            nn.ReLU(inplace=True)\n",
        "        ]\n",
        "        in_features = out_features\n",
        "        \n",
        "        # Downsampling\n",
        "        for _ in range(2):\n",
        "            out_features *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "        \n",
        "        # Residual blocks\n",
        "        for _ in range(num_residual_block):\n",
        "            model += [ResidualBlock(out_features)]\n",
        "            \n",
        "        # Upsampling\n",
        "        for _ in range(2):\n",
        "            out_features //= 2\n",
        "            model += [\n",
        "                nn.Upsample(scale_factor=2), # --> width*2, heigh*2\n",
        "                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "            \n",
        "        # Output Layer\n",
        "        model += [nn.ReflectionPad2d(channels),\n",
        "                  nn.Conv2d(out_features, channels, 7),\n",
        "                  nn.Tanh()\n",
        "                 ]\n",
        "        \n",
        "        # Unpacking\n",
        "        self.model = nn.Sequential(*model) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "VpvoXRnkW3hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discrimator\n"
      ],
      "metadata": {
        "id": "xdiU2tLNW56k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        channels, height, width = input_shape\n",
        "        \n",
        "        # Calculate output shape of image discriminator (PatchGAN)\n",
        "        self.output_shape = (1, height//2**4, width//2**4)\n",
        "        \n",
        "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
        "            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n",
        "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_filters))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "        \n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(channels, 64, normalize=False),\n",
        "            *discriminator_block(64, 128),\n",
        "            *discriminator_block(128,256),\n",
        "            *discriminator_block(256,512),\n",
        "            nn.ZeroPad2d((1,0,1,0)),\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, img):\n",
        "        return self.model(img)"
      ],
      "metadata": {
        "id": "6rO16BZ-XEUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Losses"
      ],
      "metadata": {
        "id": "De2RU9CFXT54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()"
      ],
      "metadata": {
        "id": "5k-H5GH5XUGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Models/optimizers"
      ],
      "metadata": {
        "id": "qjh7q4ahYWWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (channels, img_height, img_width) # (3,256,256)\n",
        "n_residual_blocks = 9 # suggested default, number of residual blocks in generator\n",
        "\n",
        "G_AB = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "G_BA = GeneratorResNet(input_shape, n_residual_blocks)\n",
        "D_A = Discriminator(input_shape)\n",
        "D_B = Discriminator(input_shape)\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "if cuda:\n",
        "    G_AB = G_AB.cuda()\n",
        "    G_BA = G_BA.cuda()\n",
        "    D_A = D_A.cuda()\n",
        "    D_B = D_B.cuda()\n",
        "    \n",
        "    criterion_GAN.cuda()\n",
        "    criterion_cycle.cuda()\n",
        "    criterion_identity.cuda()"
      ],
      "metadata": {
        "id": "nhpuOdavXY0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "# lr = 0.0002\n",
        "# b1 = 0.5\n",
        "# b2 = 0.999\n",
        "\n",
        "optimizer_G = torch.optim.Adam(\n",
        "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1,b2)\n",
        ")\n",
        "\n",
        "optimizer_D_A = torch.optim.Adam(\n",
        "    D_A.parameters(), lr=lr, betas=(b1,b2)\n",
        ")\n",
        "optimizer_D_B = torch.optim.Adam(\n",
        "    D_B.parameters(), lr=lr, betas=(b1,b2)\n",
        ")"
      ],
      "metadata": {
        "id": "PxK2WHfTXh1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA"
      ],
      "metadata": {
        "id": "HMclGxmtYUTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transforms_ = [\n",
        "    transforms.Resize(int(img_height*1.12), Image.BICUBIC),\n",
        "    transforms.RandomCrop((img_height, img_width)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]"
      ],
      "metadata": {
        "id": "Qy08jRcxXq00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LambdaLR:\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "        \n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch+self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "# n_epochs = 10\n",
        "# epoch = 0\n",
        "# decay_epoch = 5\n",
        "\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_G,\n",
        "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
        ")\n",
        "\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_D_A,\n",
        "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
        ")\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_D_B,\n",
        "    lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n",
        ")"
      ],
      "metadata": {
        "id": "GLsVyhy7Xrr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_rgb(image):\n",
        "    rgb_image = Image.new(\"RGB\", image.size)\n",
        "    rgb_image.paste(image)\n",
        "    return rgb_image"
      ],
      "metadata": {
        "id": "HzSKz71QXryX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.unaligned = unaligned\n",
        "        self.mode = mode\n",
        "        if self.mode == 'train':\n",
        "            self.files_A = sorted(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*')[:250])\n",
        "            self.files_B = sorted(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*')[:250])\n",
        "        elif self.mode == 'test':\n",
        "            self.files_A = sorted(glob.glob(os.path.join(root+'/monet_jpg')+'/*.*')[250:])\n",
        "            self.files_B = sorted(glob.glob(os.path.join(root+'/photo_jpg')+'/*.*')[250:301])\n",
        "\n",
        "    def  __getitem__(self, index):\n",
        "        image_A = Image.open(self.files_A[index % len(self.files_A)])\n",
        "        \n",
        "        if self.unaligned:\n",
        "            image_B = Image.open(self.files_B[np.random.randint(0, len(self.files_B)-1)])\n",
        "        else:\n",
        "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
        "        if image_A.mode != 'RGB':\n",
        "            image_A = to_rgb(image_A)\n",
        "        if image_B.mode != 'RGB':\n",
        "            image_B = to_rgb(image_B)\n",
        "            \n",
        "        item_A = self.transform(image_A)\n",
        "        item_B = self.transform(image_B)\n",
        "        return {'A':item_A, 'B':item_B}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))\n",
        "            "
      ],
      "metadata": {
        "id": "fzN3vnBeYA-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    ImageDataset(root, transforms_=transforms_, unaligned=True),\n",
        "    batch_size=1, # 1\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu # 3\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(root, transforms_=transforms_, unaligned=True, mode='test'),\n",
        "    batch_size=5,\n",
        "    shuffle=True,\n",
        "    num_workers=n_cpu\n",
        ")"
      ],
      "metadata": {
        "id": "zyIlkqsDYGQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "q-nVADuzYRiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epoch, n_epochs):\n",
        "    for i, batch in enumerate(tqdm(dataloader)):\n",
        "        \n",
        "        # Set model input\n",
        "        real_A = batch['A'].type(Tensor)\n",
        "        real_B = batch['B'].type(Tensor)\n",
        "        \n",
        "        # Adversarial ground truths\n",
        "        valid = Tensor(np.ones((real_A.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n",
        "        fake = Tensor(np.zeros((real_A.size(0), *D_A.output_shape))) # requires_grad = False. Default.\n",
        "        \n",
        "# -----------------\n",
        "# Train Generators\n",
        "# -----------------\n",
        "        G_AB.train() # train mode\n",
        "        G_BA.train() # train mode\n",
        "        \n",
        "        optimizer_G.zero_grad() # Integrated optimizer(G_AB, G_BA)\n",
        "        \n",
        "        # Identity Loss\n",
        "        loss_id_A = criterion_identity(G_BA(real_A), real_A) # If you put A into a generator that creates A with B,\n",
        "        loss_id_B = criterion_identity(G_AB(real_B), real_B) # then of course A must come out as it is.\n",
        "                                                             # Taking this into consideration, add an identity loss that simply compares 'A and A' (or 'B and B').\n",
        "        loss_identity = (loss_id_A + loss_id_B)/2\n",
        "        \n",
        "        # GAN Loss\n",
        "        fake_B = G_AB(real_A) # fake_B is fake-photo that generated by real monet-drawing\n",
        "        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid) # tricking the 'fake-B' into 'real-B'\n",
        "        fake_A = G_BA(real_B)\n",
        "        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid) # tricking the 'fake-A' into 'real-A'\n",
        "        \n",
        "        loss_GAN = (loss_GAN_AB + loss_GAN_BA)/2\n",
        "        \n",
        "        # Cycle Loss\n",
        "        recov_A = G_BA(fake_B) # recov_A is fake-monet-drawing that generated by fake-photo\n",
        "        loss_cycle_A = criterion_cycle(recov_A, real_A) # Reduces the difference between the restored image and the real image\n",
        "        recov_B = G_AB(fake_A)\n",
        "        loss_cycle_B = criterion_cycle(recov_B, real_B)\n",
        "        \n",
        "        loss_cycle = (loss_cycle_A + loss_cycle_B)/2\n",
        "        \n",
        "# ------> Total Loss\n",
        "        loss_G = loss_GAN + (10.0*loss_cycle) + (5.0*loss_identity) # multiply suggested weight(default cycle loss weight : 10, default identity loss weight : 5)\n",
        "        \n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "        \n",
        "# -----------------\n",
        "# Train Discriminator A\n",
        "# -----------------\n",
        "        optimizer_D_A.zero_grad()\n",
        "    \n",
        "        loss_real = criterion_GAN(D_A(real_A), valid) # train to discriminate real images as real\n",
        "        loss_fake = criterion_GAN(D_A(fake_A.detach()), fake) # train to discriminate fake images as fake\n",
        "        \n",
        "        loss_D_A = (loss_real + loss_fake)/2\n",
        "        \n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "# -----------------\n",
        "# Train Discriminator B\n",
        "# -----------------\n",
        "        optimizer_D_B.zero_grad()\n",
        "    \n",
        "        loss_real = criterion_GAN(D_B(real_B), valid) # train to discriminate real images as real\n",
        "        loss_fake = criterion_GAN(D_B(fake_B.detach()), fake) # train to discriminate fake images as fake\n",
        "        \n",
        "        loss_D_B = (loss_real + loss_fake)/2\n",
        "        \n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "        \n",
        "# ------> Total Loss\n",
        "        loss_D = (loss_D_A + loss_D_B)/2\n",
        "    \n",
        "# -----------------\n",
        "# Show Progress\n",
        "# -----------------\n",
        "        if (i+1) % 50 == 0:\n",
        "            sample_images()\n",
        "            print('[Epoch %d/%d] [Batch %d/%d] [D loss : %f] [G loss : %f - (adv : %f, cycle : %f, identity : %f)]'\n",
        "                    %(epoch+1,n_epochs,       # [Epoch -]\n",
        "                      i+1,len(dataloader),   # [Batch -]\n",
        "                      loss_D.item(),       # [D loss -]\n",
        "                      loss_G.item(),       # [G loss -]\n",
        "                      loss_GAN.item(),     # [adv -]\n",
        "                      loss_cycle.item(),   # [cycle -]\n",
        "                      loss_identity.item(),# [identity -]\n",
        "                     ))\n"
      ],
      "metadata": {
        "id": "etIlNfNiYQgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}